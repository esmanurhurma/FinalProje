---
title: "Proje Rapor : Esmanur Hurma 190401002"
output:
  html_document:
    df_print: paged
---

# Q1 : Problem tanımı

Şirketimiz **Inferno Orange Dynamics Gönüllü Kuruluş**. Problemimiz *"Siber Güvenlik için Ağ Trafiği Analizi Veri Kümesi" üzerinde çalışarak, saldırıların en çok hangi protokol üzerinden manipüle edildiğini bilgine ulaşmak ve protokol üzerinde gerçekleşme ihtimali en yüksek olan saldırıyı belirlemek*.

# Q2 : Proje Amacı

[Cyber Threat Data for New Malware Attacks](https://www.kaggle.com/datasets/zunxhisamniea/cyber-threat-data-for-new-malware-attacks/data) adlı Kaggle veri setini kullanarak iş problemini *Decision Trees* ve **Random Forests** modellemeleri kullanarak çözmeyi amaçlıyoruz. Bu sayede problemin çözümüyle kar arttırımına katkıda bulunmayı planlıyoruz.

# Q3 : Veri seti keşifsel analizi

Bu kısımda kullanılacak olan temel R kütüphaneleri yüklenir. readr veri okuma işlemleri için, dplyr veri manipülasyonu için, VIM eksik veri görselleştirmesi için kullanılır. Model eğitimi için Random Forest kullanılır.

```{r}
# Gerekli kütüphaneleri yükle
library(readr)
library(dplyr)
library(VIM)
library(randomForest)
```

cyberthreat.csv adlı veri seti, belirtilen dosya yolundan okunur ve myDF isimli bir veri çerçevesine atanır. Veri çerçevesinin satır ve sütun sayıları ekrana yazdırılır.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Kaggle'dan indirilen CSV dosyasının yolu
dosya_yolu <- "C:/Users/Casper/final/cyberthreat.csv"

# CSV dosyasını read_csv() fonksiyonu ile oku
myDF <- readr::read_csv(dosya_yolu)

# Veri boyutlarını göster
cat("Satır Sayısı:", nrow(myDF), "\n")
cat("Sütun Sayısı:", ncol(myDF), "\n")

# Değişkenin tipini göster
cat("Değişken Tipi:", class(myDF)[[1]], "\n")
```

Veri setinin yapısını detaylı bir şekilde sunarak sütun adları, veri tipleri ve ilk değerleri içeren bilgilere bakıldı. Temel istatistiksel özellikleri sunarak her sütunun genel dağılımını gösterildi. Her sütunun veri tipini belirleyerek veri setindeki değişken türlerini gösterildi. Son olarak her sütundaki eksik (NA) değerlerin sayısını hesaplar, böylece eksik verilerin dağılımını anlamak mümkün olur. Bu adımlar, veri setinin genel yapısını ve potansiyel eksik verileri anlamak adına önemlidir.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Veri Seti Hakkında Genel Bilgiler:
# Veri setinin yapısal özellikleri
str(myDF)

# Temel istatistikler
summary(myDF)

# Sütun Tiplerini Kontrol Etme:
# Veri setindeki sütun türleri
sapply(myDF, class)

# Eksik Veri Kontrolü:
# Her sütundaki eksik değer sayıları
colSums(is.na(myDF))
```

# Q4 : Veri seti ön işlemesi

```{r echo=FALSE, message=FALSE, warning=FALSE}
install.packages("VIM")
library(VIM)
# Eksik değerleri görselleştirme
aggr_plot <- aggr(myDF, col=c('navajowhite1', 'navajowhite3'), numbers=TRUE, sortVars=TRUE, labels=names(myDF), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))

# Veri Dağılımını Görselleştirme:
# Histogram örneği (sadece numeric sütunlar için)
str(myDF)

# Hangi sütunların sayısal olduğunu kontrol et
numeric_columns <- sapply(myDF, is.numeric)
numeric_columns_names <- names(numeric_columns[numeric_columns])
print(numeric_columns_names)

# Histogram örneği (sadece numeric sütunlar için)
hist(myDF$`Source Port`, main = "Source Port Distribution", xlab = "Values", col = "lightblue")
hist(myDF$`Destination Port`, main = "Destination Port Distribution", xlab = "Values", col = "lightblue")
hist(myDF$`Packet Size`, main = "Packet Size Distribution", xlab = "Values", col = "lightblue")
# dplyr paketini yükle
library(dplyr)

# Belirli sütunları kaldır
myDF <- myDF %>%
  select(-`Flag`, -`Source IP Address`, -`Destination IP Address`)

# Veri setinin sütun isimlerini kontrol et
colnames(myDF)
```

Veri setinin temel özelliklerini ve dağılımlarını incelemek için ilk olarak, veri setinin tipi, yapısal özellikleri ve temel istatistikleri gösterildi. Daha sonra, sütun türlerinin kontrolü ve eksik veri kontrolü yapıldı. Eksik verilerin görselleştirilmesi için *VIM* paketi kullanıldı. Son olarak, sayısal sütunlara ait histogramlar çizildi. *Bu adımların amacı, veri setinin genel yapısını anlamak, sayısal değişkenlerin dağılımlarını görselleştirmek ve olası anormallikleri belirlemektir.*

# Q5 : Veri mühendisliği

İlk olarak, veri seti hakkında genel bilgiler alınıyor; yapısal özellikler, temel istatistikler ve sütun tipleri inceleniyor. Eksik veri kontrolü yapılıyor ve eksik değerlerin görselleştirmesi sağlanıyor. Sayısal sütunlar için histogramlar çizilip belirli sütunlar kaldırılıyor. Sonrasında, veri seti model eğitimi için train ve test olarak ayrılıyor, hedef değişken faktöryel hale getirilip randomForest algoritması ile bir model eğitiliyor.

Eğitilen model kullanılarak test verisi üzerinde tahminler yapılıyor ve accuracy hesaplanıyor. Precision, Recall ve F1-score gibi performans metrikleri hesaplanarak sonuçlar görselleştiriliyor. Bu süreç, veri setinin analiz edilmesi, önişleme adımları ve sınıflandırma modelinin eğitilip değerlendirilmesini içeriyor.

# Q6 : Veri analizi

Random Forest sınıflandırma modeli oluşturarak siber güvenlik tehditlerini tahmin etmeyi amaçlar. İlk olarak, veri seti %80 eğitim ve %20 test olacak şekilde ayrılır. Hedef değişken "Target Variable" faktöryel hale getirilir.

Ardından, eğitim verisi kullanılarak Random Forest modeli oluşturulur (ntree = 100). Test verisi üzerinde yapılan tahminlerle bir Confusion Matrix elde edilir ve modelin doğruluğu (Accuracy) hesaplanır.

Precision, Recall ve F1-score gibi performans metrikleri de bu Confusion Matrix üzerinden hesaplanır ve sonuçlar bir veri çerçevesinde görselleştirilir. Bu süreç, veri seti üzerinde eğitim ve test setleri oluşturmayı, bir sınıflandırma modeli eğitmeyi ve modelin performansını değerlendirmeyi içerir.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Gerekli kütüphaneleri yükle
install.packages("randomForest")
library(randomForest)

# Model için veriyi ayırma
set.seed(123)  
sample_index <- sample(1:nrow(myDF), 0.8 * nrow(myDF))  # %80 train, %20 test
train_data <- myDF[sample_index, ]
test_data <- myDF[-sample_index, ]

colnames(train_data)

# Hedef değişkeni faktöryel hale getirme
train_data$`Target Variable` <- as.factor(train_data$`Target Variable`)

# Modeli eğitme
model <- randomForest(`Target Variable` ~ Protocol + Packet, data = train_data, ntree = 100)

# Test verisi üzerinde tahmin yapma
predictions <- predict(model, test_data)

# Confusion matrix ve accuracy hesaplama
conf_matrix <- table(predictions, test_data$`Target Variable`)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
conf_matrix
cat("Accuracy:", accuracy, "\n")

# Precision, Recall ve F1-score hesaplama
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f1_score <- 2 * (precision * recall) / (precision + recall)

# Metrikleri görselleştirme
metrics_df <- data.frame(Precision = precision, Recall = recall, F1_Score = f1_score)
print("Precision, Recall ve F1-score:")
print(metrics_df)
```

# Q7 : Sonuç değerlendirme, tavsiyeler

Veri Seti Boyutu: Veri setinin boyutu genişletilebilir. Daha fazla örnek veri eklenmesi, modelin genelleme yeteneğini artırabilir ve daha çeşitli senaryolara adapte olmasına yardımcı olabilir.

Özellik Seçimi: Modelde kullanılan özelliklerin (Protocol, Packet vb.) seçimi üzerinde daha fazla analiz yapılabilir. Belki de farklı özellik kombinasyonları veya yeni özellikler eklemek modelin performansını artırabilir.

Model Ayarları: Random Forest modelinin hiperparametreleri (örneğin, ntree) belirli bir veri seti için optimal olabilir, ancak farklı ayarlarla denemeler yapmak, modelin daha iyi performans göstermesine olanak tanır.

Değerlendirme Metrikleri: Modelin başarı ölçütleri olarak kullanılan Precision, Recall ve F1-score metriklerinin yanı sıra, başka metrikler de incelenebilir. ROC eğrisi veya AUC değerleri gibi metrikler modelin performansını daha kapsamlı bir şekilde değerlendirebilir.

Eksik Veri ve Temizlik: Veri setinde eksik veya hatalı değerler varsa, bu durumları ele almak ve temizlik yapmak modelin güvenilirliğini artırabilir.

Farklı Modellerin Karşılaştırılması: Random Forest dışında başka sınıflandırma modelleri de denenebilir. Bu, en iyi modelin seçilmesine yardımcı olabilir.

Eğitim ve Test Verileri Dengeleme: Eğitim ve test veri setleri arasındaki sınıf dengesizliği göz önüne alınmalıdır. Sınıflar arasındaki dengesizlik, modelin bazı sınıfları daha iyi tahmin etmesine neden olabilir.

Bu değerlendirme ve tavsiyeler, modelin daha güçlü ve genelleme yapabilen bir yapıya sahip olmasına yardımcı olabilir.
